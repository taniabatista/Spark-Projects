{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import DataFrameReader, SQLContext, SparkSession\n",
    "\n",
    "try:\n",
    "    sc.stop() \n",
    "except:\n",
    "    pass\n",
    "sc = pyspark.SparkContext(master='spark://172.17.0.3:7077', appName='app15')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEC1\n",
    "\n",
    "![pokemon](https://kaggle2.blob.core.windows.net/datasets-images/2619/4359/e3ef5846d64dc9a747afd82273456328/dataset-cover.jpg)\n",
    "\n",
    "# Ejercicio 1: Operaciones básicas\n",
    "## 1.1 Lectura de datos CSV y renombrado de columnas\n",
    "Lee en un DataFrame el contenido de los datos que están en el CSV con la siguiente ruta: `data/pokemon/pokemon.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombra las columnas del dataframe para que sean las siguientes:\n",
    "\n",
    "`\"id\", \"name\", \"type_1\", \"type_2\", \"hp\", \"attack\", \"defense\", \"special_attack\", \"special_defense\", \"speed\", \"generation\", \"legendary\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext = pyspark.SQLContext(sc)\n",
    "\n",
    "\n",
    "df = sqlContext.read.format(\"csv\").load(\"hdfs://172.17.0.9:8020/ejemplo1/pokemon.csv\", header=True).toDF(\"id\", \"name\", \"type_1\", \"type_2\", \"hp\", \"attack\", \"defense\", \"special_attack\", \"special_defense\", \"speed\", \"generation\", \"legendary\")\n",
    "df.createOrReplaceTempView(\"pokemon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Comprobación de lectura y esquema\n",
    "¿Cómo puedes comprobar el esquema que ha inferido Spark al leer el CSV?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type_1: string (nullable = true)\n",
      " |-- type_2: string (nullable = true)\n",
      " |-- hp: string (nullable = true)\n",
      " |-- attack: string (nullable = true)\n",
      " |-- defense: string (nullable = true)\n",
      " |-- special_attack: string (nullable = true)\n",
      " |-- special_defense: string (nullable = true)\n",
      " |-- speed: string (nullable = true)\n",
      " |-- generation: string (nullable = true)\n",
      " |-- legendary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas ocasiones, al leer un CSV, que no se \"parsea\" correctamente, y las columnas pueden contener contenido parcial ó erróneo.\n",
    "\n",
    "¿Cómo puedes comprobar que la lectura de los datos se ha realizado bien y que los campos no están \"descolocados\"? \n",
    "\n",
    "Fíjate sólo en la primera fila del DataFrame para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+---+------+-------+--------------+---------------+-----+----------+---------+\n",
      "| id|     name|type_1|type_2| hp|attack|defense|special_attack|special_defense|speed|generation|legendary|\n",
      "+---+---------+------+------+---+------+-------+--------------+---------------+-----+----------+---------+\n",
      "|  1|Bulbasaur| Grass|Poison| 45|    49|     49|            65|             65|   45|         1|    False|\n",
      "+---+---------+------+------+---+------+-------+--------------+---------------+-----+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Crees que Spark ha inferido bien el esquema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "#Si, pero no tiene los tipo de datos correctos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cambiarías el tipo de alguna columna? ¿En caso afirmativo, cómo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- type_1: string (nullable = true)\n",
      " |-- type_2: string (nullable = true)\n",
      " |-- hp: integer (nullable = true)\n",
      " |-- attack: integer (nullable = true)\n",
      " |-- defense: integer (nullable = true)\n",
      " |-- special_attack: integer (nullable = true)\n",
      " |-- special_defense: integer (nullable = true)\n",
      " |-- speed: integer (nullable = true)\n",
      " |-- generation: integer (nullable = true)\n",
      " |-- legendary: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "df2 = df.select(df['name'].cast('string')\n",
    "                , df['type_1'].cast('string')\n",
    "                , df['type_2'].cast('string')\n",
    "                , df['hp'].cast('integer')\n",
    "                , df['attack'].cast('integer')\n",
    "                , df['defense'].cast('integer')\n",
    "                , df['special_attack'].cast('integer')\n",
    "                , df['special_defense'].cast('integer')\n",
    "                , df['speed'].cast('integer')\n",
    "                , df['generation'].cast('integer')\n",
    "                , df['legendary'].cast('boolean')) \n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Transformaciones sobre el DataFrame\n",
    "Realiza las siguientes operaciones sobre el DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Filtra las filas que no tengan un mínimo de 50 de `hp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext.sql(\"select * from pokemon where hp>50\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Agrupa todas las filas por el valor de la columna `type_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  type_1|\n",
      "+--------+\n",
      "|   Water|\n",
      "|  Poison|\n",
      "|   Steel|\n",
      "|    Rock|\n",
      "|     Ice|\n",
      "|   Ghost|\n",
      "|   Fairy|\n",
      "| Psychic|\n",
      "|  Dragon|\n",
      "|  Flying|\n",
      "|     Bug|\n",
      "|Electric|\n",
      "|    Fire|\n",
      "|  Ground|\n",
      "|    Dark|\n",
      "|Fighting|\n",
      "|   Grass|\n",
      "|  Normal|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext.sql(\"select first(type_1) as type_1 from pokemon group by type_1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Obtén el tamaño de cada grupo (es decir, cuántos pokemon de cada grupo hay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|  type_1|cant|\n",
      "+--------+----+\n",
      "|   Water| 112|\n",
      "|  Poison|  28|\n",
      "|   Steel|  27|\n",
      "|    Rock|  44|\n",
      "|     Ice|  24|\n",
      "|   Ghost|  32|\n",
      "|   Fairy|  17|\n",
      "| Psychic|  57|\n",
      "|  Dragon|  32|\n",
      "|  Flying|   4|\n",
      "|     Bug|  69|\n",
      "|Electric|  44|\n",
      "|    Fire|  52|\n",
      "|  Ground|  32|\n",
      "|    Dark|  31|\n",
      "|Fighting|  27|\n",
      "|   Grass|  70|\n",
      "|  Normal|  98|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext.sql(\"select first(type_1) as type_1,count(type_1) as cant from pokemon group by type_1\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Quédate sólo con los 10 grupos más grandes, ordenados de mayor a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|  type_1|cant|\n",
      "+--------+----+\n",
      "|   Water| 112|\n",
      "|  Normal|  98|\n",
      "|   Grass|  70|\n",
      "|     Bug|  69|\n",
      "| Psychic|  57|\n",
      "|    Fire|  52|\n",
      "|Electric|  44|\n",
      "|    Rock|  44|\n",
      "|  Ground|  32|\n",
      "|   Ghost|  32|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext.sql(\"select first(type_1) as type_1,count(type_1) as cant from pokemon group by type_1 order by cant desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Trae a memoria, como un array de Rows, el resultado (los 10 grupos más grandes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqlContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7da7b7004475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Incluye aquí tu respuesta ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0marreglo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select first(type_1) as type_1,count(type_1) as cant from pokemon group by type_1 order by cant desc limit 10\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sqlContext' is not defined"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "arreglo = sqlContext.sql(\"select first(type_1) as type_1,count(type_1) as cant from pokemon group by type_1 order by cant desc limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.6 De todos los anteriores pasos de este apartado 1.3 ¿cuáles son transformaciones y cuáles acciones? ¿por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Más operaciones sobre DataFrames\n",
    "\n",
    "## 2.1 Contando elementos distintos\n",
    "Queremos saber cuántos grupos distintos de pokemon **del conjunto de datos original** existen teniendo en cuenta sus dos tipos (`type_1` y `type_2`).\n",
    "\n",
    "Por ejemplo, si nuestro conjunto de datos fuera éste:\n",
    "\n",
    "|id|type_1|type_2|\n",
    "---|-------|-----|\n",
    "|1  |Water  |Grass|\n",
    "|2  |Fire   |Rock |\n",
    "|3  |Fire   |     |\n",
    "|4  |Water  |Grass|\n",
    "\n",
    "Entonces, la respuesta sería **3** (hay 3 grupos diferentes: `(Water, Grass)`,`(Fire, Rock)` y`(Fire, null)`\n",
    "\n",
    "¿Cómo sacarías el número de grupos diferentes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "sqlContext.sql(\"select type_1,type_2 from pokemon group by type_1,type_2\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Muestra Aleatoria\n",
    "¿Cómo extraerías una muestra aleatoria de un 15% **del conjunto de datos original**?\n",
    "\n",
    "¿Qué tamaño esperarías que debería tener esa muestra?\n",
    "\n",
    "¿Qué tamaño ha resultado tener después de calcularla?\n",
    "\n",
    "¿Porqué crees que no es exactamente el tamaño esperado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Incluye aquí tus respuestas ###\n",
    "seed = 11\n",
    "withReplacement = False\n",
    "fraction = 0.15\n",
    "df2.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Reparticionado y escritura a disco\n",
    "¿Cuántas particiones tiene tu DataFrame?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "df2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe tu DataFrame, en formato CSV, en la siguiente ruta: `data/output/pokemon_default`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "#Note que el nuevos archivos csv se almacena en un hadoop cluster \n",
    "df2.write.csv(\"hdfs://172.17.0.9:8020/ejemplo1/pokemon_default.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿cuántos ficheros se han generado? ¿Por qué crees que se ha generado ese número de ficheros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "#solo uno porque solo hay un partición de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo harías para escribir 4 ficheros de salida en la ruta `data/output/four_files`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "repartitioned = df2.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repartitioned.write.csv(\"data/output/pokemon_default/four_files/mi_dataset_4.csv\")\n",
    "#Note que el nuevos archivos csv se almacena en un hadoop cluster \n",
    "df2.repartition(4).write.csv(\"hdfs://172.17.0.9:8020/ejemplo1/pokemon_default_4.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Creando nuevas columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Nueva columna booleana\n",
    "Crea una nueva columna, que se llame `strong`, de tipo booleano, que indique si un pokemon tiene más de 75 en `hp` y en alguna de las columnas `attack` ó `defense`.\n",
    "Es decir, si nuestro dataset fuera:\n",
    "\n",
    "|id|hp|attack|defense|\n",
    "---|--|-----|-----|\n",
    "|1  |50|90  |90|\n",
    "|2  |80|35   |78 |\n",
    "|3  |60|30   | 75|\n",
    "|4  |90|60  |60|\n",
    "\n",
    "El resultado esperado sería:\n",
    "\n",
    "\n",
    "|id|hp|attack|defense|strong|\n",
    "---|--|-----|-----|---------|\n",
    "|1  |50|90  |90| false|\n",
    "|2  |80|35   |78 | true|\n",
    "|3  |60|30   | 75| false|\n",
    "|4  |90|60  |60| false|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n",
      "| hp|attack|defense|strong|\n",
      "+---+------+-------+------+\n",
      "| 80|    82|     83|  true|\n",
      "| 80|   100|    123|  true|\n",
      "| 78|    84|     78|  true|\n",
      "| 78|   130|    111|  true|\n",
      "| 78|   104|     78|  true|\n",
      "| 59|    63|     80| false|\n",
      "| 79|    83|    100|  true|\n",
      "| 79|   103|    120|  true|\n",
      "| 65|    90|     40| false|\n",
      "| 65|   150|     40| false|\n",
      "| 83|    80|     75|  true|\n",
      "| 83|    80|     80|  true|\n",
      "| 55|    81|     60| false|\n",
      "| 65|    90|     65| false|\n",
      "| 60|    85|     69| false|\n",
      "| 60|    90|     55| false|\n",
      "| 50|    75|     85| false|\n",
      "| 75|   100|    110| false|\n",
      "| 90|    92|     87|  true|\n",
      "| 81|   102|     77|  true|\n",
      "+---+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "from pyspark.sql.functions import col\n",
    "df2.withColumn(\"strong\",col(\"hp\")>75).where(\"attack>75 OR defense>74\").select(\"hp\",\"attack\",\"defense\",\"strong\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Nueva columna numérica\n",
    "Nos hemos inventado una nueva cualidad de los pokemon, `stamina` que responde a la fórmula:\n",
    "\n",
    "\\begin{align}\n",
    "\\ \\frac{(hp^2 * attack)}{speed * defense}\n",
    "\\end{align}\n",
    "\n",
    "Crea una nueva columna `stamina` con el valor para cada pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+------+-----+-------+------------------+\n",
      "|            name| hp|attack|speed|defense|           stamina|\n",
      "+----------------+---+------+-----+-------+------------------+\n",
      "|       Bulbasaur| 45|    49|   45|     49|              45.0|\n",
      "|         Ivysaur| 60|    62|   60|     63| 59.04761904761905|\n",
      "|        Venusaur| 80|    82|   80|     83| 79.03614457831326|\n",
      "|   Mega Venusaur| 80|   100|   80|    123| 65.04065040650407|\n",
      "|      Charmander| 39|    52|   65|     43| 28.29767441860465|\n",
      "|      Charmeleon| 58|    64|   80|     58|              46.4|\n",
      "|       Charizard| 78|    84|  100|     78|             65.52|\n",
      "|Mega Charizard X| 78|   130|  100|    111| 71.25405405405405|\n",
      "|Mega Charizard Y| 78|   104|  100|     78|             81.12|\n",
      "|        Squirtle| 44|    48|   43|     65|  33.2479427549195|\n",
      "|       Wartortle| 59|    63|   58|     80|  47.2635775862069|\n",
      "|       Blastoise| 79|    83|   78|    100| 66.41064102564103|\n",
      "|  Mega Blastoise| 79|   103|   78|    120| 68.67767094017094|\n",
      "|        Caterpie| 45|    30|   45|     35| 38.57142857142857|\n",
      "|         Metapod| 50|    20|   30|     55|30.303030303030305|\n",
      "|      Butterfree| 60|    45|   70|     50|46.285714285714285|\n",
      "|          Weedle| 40|    35|   50|     30|37.333333333333336|\n",
      "|          Kakuna| 45|    25|   35|     50|28.928571428571427|\n",
      "|        Beedrill| 65|    90|   75|     40|            126.75|\n",
      "|   Mega Beedrill| 65|   150|  145|     40|109.26724137931035|\n",
      "+----------------+---+------+-----+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "from pyspark.sql.functions import pow\n",
    "df2.withColumn(\"stamina\",(pow(col(\"hp\"),2)*col(\"attack\"))/(col(\"speed\")*col(\"defense\"))).\\\n",
    "    select(\"name\",\"hp\",\"attack\",\"speed\",\"defense\",\"stamina\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Nueva columna a partir de extracción sobre strings\n",
    "Crea una nueva columna que tenga como valor \"Mega\" si el nombre del pokemon contiene la palabra \"Mega\" o null en otro caso.\n",
    "Pista: utiliza una expresión regular para hacer una extracción sobre la columna `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+\n",
      "|            name|Mega|\n",
      "+----------------+----+\n",
      "|       Bulbasaur|null|\n",
      "|         Ivysaur|null|\n",
      "|        Venusaur|null|\n",
      "|   Mega Venusaur|Mega|\n",
      "|      Charmander|null|\n",
      "|      Charmeleon|null|\n",
      "|       Charizard|null|\n",
      "|Mega Charizard X|Mega|\n",
      "|Mega Charizard Y|Mega|\n",
      "|        Squirtle|null|\n",
      "|       Wartortle|null|\n",
      "|       Blastoise|null|\n",
      "|  Mega Blastoise|Mega|\n",
      "|        Caterpie|null|\n",
      "|         Metapod|null|\n",
      "|      Butterfree|null|\n",
      "|          Weedle|null|\n",
      "|          Kakuna|null|\n",
      "|        Beedrill|null|\n",
      "|   Mega Beedrill|Mega|\n",
      "+----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "from pyspark.sql import functions as F\n",
    "df2.withColumn(\"Mega\",F.when(col(\"name\").like(\"%Mega%\"),\"Mega\").otherwise(None)).select(\"name\",\"Mega\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Nueva Columna de tipo complejo\n",
    "Por último, queremos crear una nueva columna `properties`,  que sea un `Map` que contenga las propiedades  más importantes de cada pokemon.\n",
    "En concreto, queremos que tenga las siguientes claves y valores:\n",
    "\n",
    "```python\n",
    "{ name -> \"name\",\n",
    "  type -> \"type_1\",\n",
    "  hp -> hp,\n",
    "  attack -> attack,\n",
    "  defense -> defense\n",
    "}```\n",
    "\n",
    "¿Cómo crearías esta nueva columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------------------------------------------------------------------+\n",
      "|name            |properties                                                                          |\n",
      "+----------------+------------------------------------------------------------------------------------+\n",
      "|Bulbasaur       |Map(defense -> 49, name -> Bulbasaur, attack -> 49, hp -> 45, type -> Grass)        |\n",
      "|Ivysaur         |Map(defense -> 63, name -> Ivysaur, attack -> 62, hp -> 60, type -> Grass)          |\n",
      "|Venusaur        |Map(defense -> 83, name -> Venusaur, attack -> 82, hp -> 80, type -> Grass)         |\n",
      "|Mega Venusaur   |Map(defense -> 123, name -> Mega Venusaur, attack -> 100, hp -> 80, type -> Grass)  |\n",
      "|Charmander      |Map(defense -> 43, name -> Charmander, attack -> 52, hp -> 39, type -> Fire)        |\n",
      "|Charmeleon      |Map(defense -> 58, name -> Charmeleon, attack -> 64, hp -> 58, type -> Fire)        |\n",
      "|Charizard       |Map(defense -> 78, name -> Charizard, attack -> 84, hp -> 78, type -> Fire)         |\n",
      "|Mega Charizard X|Map(defense -> 111, name -> Mega Charizard X, attack -> 130, hp -> 78, type -> Fire)|\n",
      "|Mega Charizard Y|Map(defense -> 78, name -> Mega Charizard Y, attack -> 104, hp -> 78, type -> Fire) |\n",
      "|Squirtle        |Map(defense -> 65, name -> Squirtle, attack -> 48, hp -> 44, type -> Water)         |\n",
      "|Wartortle       |Map(defense -> 80, name -> Wartortle, attack -> 63, hp -> 59, type -> Water)        |\n",
      "|Blastoise       |Map(defense -> 100, name -> Blastoise, attack -> 83, hp -> 79, type -> Water)       |\n",
      "|Mega Blastoise  |Map(defense -> 120, name -> Mega Blastoise, attack -> 103, hp -> 79, type -> Water) |\n",
      "|Caterpie        |Map(defense -> 35, name -> Caterpie, attack -> 30, hp -> 45, type -> Bug)           |\n",
      "|Metapod         |Map(defense -> 55, name -> Metapod, attack -> 20, hp -> 50, type -> Bug)            |\n",
      "|Butterfree      |Map(defense -> 50, name -> Butterfree, attack -> 45, hp -> 60, type -> Bug)         |\n",
      "|Weedle          |Map(defense -> 30, name -> Weedle, attack -> 35, hp -> 40, type -> Bug)             |\n",
      "|Kakuna          |Map(defense -> 50, name -> Kakuna, attack -> 25, hp -> 45, type -> Bug)             |\n",
      "|Beedrill        |Map(defense -> 40, name -> Beedrill, attack -> 90, hp -> 65, type -> Bug)           |\n",
      "|Mega Beedrill   |Map(defense -> 40, name -> Mega Beedrill, attack -> 150, hp -> 65, type -> Bug)     |\n",
      "+----------------+------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Incluye aquí tu respuesta ###\n",
    "from pyspark.sql.functions import create_map,lit\n",
    "df2.withColumn(\"properties\", \n",
    "               create_map(lit(\"name\"),col(\"name\")\n",
    "                          ,lit(\"type\"),col(\"type_1\")\n",
    "                          ,lit(\"hp\"),col(\"hp\")\n",
    "                          ,lit(\"attack\"),col(\"attack\")\n",
    "                          ,lit(\"defense\"),col(\"defense\"))\n",
    "              ).select(\"name\",\"properties\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
